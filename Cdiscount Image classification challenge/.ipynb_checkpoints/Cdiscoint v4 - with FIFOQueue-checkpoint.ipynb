{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bson\n",
    "import os,io,sys\n",
    "from skimage.data import imread\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "print('All modules imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File paths\n",
    "cat_file = 'data/category_names.csv'\n",
    "train_file= 'data/train_example.bson'\n",
    "train_dir='data/train/'\n",
    "valid_dir='data/validation/'\n",
    "test_dir='data/test/'\n",
    "out_dir=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Categories :5270\n"
     ]
    }
   ],
   "source": [
    "categories = pd.read_csv(cat_file)\n",
    "print('Total Categories :'+ str(len(set(categories.category_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load bson training data\n",
    "data= bson.decode_file_iter(open(train_file,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(data)\\nfor i,d in enumerate(data):\\n    label=d['category_id']\\n    id=d['_id']\\n    img_cnt=len(d['imgs'])\\n    print(str(label)+'----' +str(id)+'-----'+str(img_cnt))\\n\""
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(data)\n",
    "for i,d in enumerate(data):\n",
    "    label=d['category_id']\n",
    "    id=d['_id']\n",
    "    img_cnt=len(d['imgs'])\n",
    "    print(str(label)+'----' +str(id)+'-----'+str(img_cnt))\n",
    "'''\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "def normalize(image_data):\n",
    "    X= image_data\n",
    "    Xmin = np.amin(image_data)\n",
    "    Xmax = np.amax(image_data)\n",
    "    \n",
    "    Xscale = (X-Xmin)/(Xmax-Xmin)\n",
    "    \n",
    "    return Xscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels One-Hot Encoded\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "one_hot_enc= LabelBinarizer()\n",
    "one_hot_labels= one_hot_enc.fit(categories.category_id)\n",
    "#print(labels[2])\n",
    "print('Labels One-Hot Encoded')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queue_input_data = tf.placeholder(tf.float32, shape=[None,180,180, 3], name='image_input')\n",
    "queue_input_target = tf.placeholder(tf.int64, shape=[None,1],name='category_id_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fifo_q_cap=100\n",
    "batch_size=100\n",
    "train_batch_cap=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = tf.FIFOQueue(capacity=fifo_q_cap, dtypes=[tf.float32, tf.int64], shapes=[[180,180,3], [1]])\n",
    "\n",
    "enqueue_op = queue.enqueue_many([queue_input_data, queue_input_target])\n",
    "dequeue_op = queue.dequeue()\n",
    "\n",
    "# tensorflow recommendation:\n",
    "# capacity = min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "data_batch, target_batch = tf.train.batch(dequeue_op, batch_size=batch_size, capacity=train_batch_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enqueue(sess,nq_size=20):\n",
    "    q_data=[]\n",
    "    q_label=[]\n",
    "    curr_data=[]\n",
    "    curr_label=[]\n",
    "    high=0\n",
    "    print(\"starting to write into queue\")\n",
    "    for i,d in enumerate(data):\n",
    "        label=d['category_id']\n",
    "        id=d['_id']\n",
    "        for e,pic in enumerate(d['imgs']):\n",
    "            picture= imread(io.BytesIO(pic['picture']))\n",
    "            norm_pic = normalize(picture)\n",
    "            q_data.append(norm_pic)\n",
    "            one_hot_label= one_hot_labels.transform(label)\n",
    "            q_label.append([one_hot_label])\n",
    "            high+=1\n",
    "            if high % nq_size==0 : \n",
    "                print(\"Enqueuing upto\", high,\" records\")\n",
    "                curr_data=q_data[0:nq_size]\n",
    "                curr_label=q_label[0:nq_size]\n",
    "                #print(str(q_label)+'----' +str(len(q_data)))\n",
    "                q_data=[]\n",
    "                q_label=[]\n",
    "                sess.run(enqueue_op, feed_dict={queue_input_data: curr_data,\n",
    "                                    queue_input_target: curr_label})\n",
    "\n",
    "print(\"finished enqueueing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "nq_size=100\n",
    "enqueue_thread = threading.Thread(target=enqueue, args=[sess, nq_size])\n",
    "enqueue_thread.isDaemon()\n",
    "enqueue_thread.start()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.DeadlineExceededError'>, Timed out waiting for notification\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-389-968533e4c95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Terminate as usual. It is safe to call `coord.request_stop()` twice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mstop_wait_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstop_grace_period_secs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_wait_secs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m       \u001b[0mstop_grace_period_secs\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mstop_wait_secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0mstop_wait_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstop_wait_secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use this to shuffle batches:\n",
    "# Fetch the data from the pipeline and put it where it belongs (into your model)\n",
    "try:\n",
    "    for i in range(5):\n",
    "        run_options = tf.RunOptions(timeout_in_ms=4000)\n",
    "        curr_data_batch, curr_label_batch = sess.run([data_batch, target_batch], options=run_options)\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "    #print(str(i)+\">>>>>>>>>>>>> :\")\n",
    "    #print(curr_label_batch)\n",
    "except Exception as e:\n",
    "  # Report exceptions to the coordinator.\n",
    "  coord.request_stop(e)\n",
    "finally:\n",
    "  # Terminate as usual. It is safe to call `coord.request_stop()` twice.\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(queue.close(cancel_pending_enqueues=True))\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Sample image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "print(\"sample image\")\n",
    "plt.imshow(picture,cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image shape\n",
    "sample_pic= np.array(picture)\n",
    "sample_pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "def normalize(image_data):\n",
    "    X= image_data\n",
    "    Xmin = np.amin(image_data)\n",
    "    Xmax = np.amax(image_data)\n",
    "    \n",
    "    Xscale = (X-Xmin)/(Xmax-Xmin)\n",
    "    \n",
    "    return Xscale\n",
    "\n",
    "\n",
    "#Test normalize\n",
    "#normalized_sample = normalize(sample_pic)\n",
    "#print(normalized_sample[170][155][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "one_hot_enc= LabelBinarizer()\n",
    "\n",
    "labels= one_hot_enc.fit_transform(labels)\n",
    "print(labels.shape)\n",
    "print('Labels One-Hot Encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([x : x for x in train_cats.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
