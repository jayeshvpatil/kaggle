{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filenames = tf.train.match_filenames_once(\"./train/*.jpg\")\n",
    "fileq = tf.train.string_input_producer(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _preprocess(image) :\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    #image = crop(image)\n",
    "    image = tf.transpose(image,[2,0,1]) #change to CHW format\n",
    "    image = (tf.cast(image,tf.float32) - 128.0)/128.0 #push in to [-1 to 1] area.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reader = tf.WholeFileReader()\n",
    "(label,image_file) = image_reader.read(fileq)\n",
    "image = tf.image.decode_jpeg(image_file,3)\n",
    "resized = tf.image.resize_images(image,[180,180],tf.image.ResizeMethod.BILINEAR)\n",
    "preprocessed = _preprocess(resized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tf.placeholder(tf.float32,shape =[None,180,180,3], name='input_')\n",
    "target_= tf.placeholder(tf.float32,shape =[None,120], name='target_')\n",
    "keep_prob= tf.placeholder(tf.float32, name='keep_prob')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters =32\n",
    "kernel_size=(5,5)\n",
    "strides=(2,2)\n",
    "\n",
    "initializer=tf.contrib.layers.xavier_initializer_conv2d()\n",
    "\n",
    "conv1 = tf.layers.conv2d(input_,filters,kernel_size,strides,padding='same',kernel_initializer=initializer)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "\n",
    "filters =64\n",
    "kernel_size=(5,5)\n",
    "strides=(2,2)\n",
    "conv2 = tf.layers.conv2d(pool1,filters,kernel_size,strides,padding='same',kernel_initializer=initializer)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool2_flat = tf.contrib.layers.flatten(pool2)\n",
    "\n",
    "num_units=512\n",
    "dense1 = tf.layers.dense(inputs=pool2_flat, units=num_units, activation=tf.nn.relu)\n",
    "dropout1 = tf.layers.dropout(inputs=dense1, rate=keep_prob)\n",
    "\n",
    "\n",
    "dense2 = tf.layers.dense(inputs=dropout1, units=256, activation=tf.nn.relu)\n",
    "dropout2 = tf.layers.dropout(inputs=dense2, rate=keep_prob)\n",
    "\n",
    "logits = tf.layers.dense(inputs=dropout2, units=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Loss (for both TRAIN and EVAL modes)\n",
    "logits = tf.identity(logits, name='logits')\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=target_ )\n",
    "\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer= tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(target_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, image_batch, label_batch, cost, accuracy):\n",
    "\n",
    "    print('Cost: {:f}'.format(session.run(cost,feed_dict={ input_: image_batch,target_: label_batch,keep_prob:1})))\n",
    "    print('Accuracy: {:f}'.format(session.run(accuracy,feed_dict={ input_: feature_batch,target_: label_batch,keep_prob:1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batch_7:0\", shape=(5, 3, 180, 180), dtype=float32) Tensor(\"batch_7:1\", shape=(5, 5), dtype=string)\n",
      "from the train set:\n",
      "Tensor(\"batch_7:0\", shape=(5, 3, 180, 180), dtype=float32)\n",
      "Tensor(\"batch_7:0\", shape=(5, 3, 180, 180), dtype=float32)\n",
      "Tensor(\"batch_7:0\", shape=(5, 3, 180, 180), dtype=float32)\n",
      "Tensor(\"batch_7:0\", shape=(5, 3, 180, 180), dtype=float32)\n",
      "Tensor(\"batch_7:0\", shape=(5, 3, 180, 180), dtype=float32)\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/RandomShuffle)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "   # initialize the variables\n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "  \n",
    "  # initialize the queue threads to start to shovel data\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    image,label = tf.train.batch(\n",
    "                                    [preprocessed,label],\n",
    "                                    batch_size=5\n",
    "                                    #,num_threads=1\n",
    "                                    )\n",
    "    print(image, label)\n",
    "    print(\"from the train set:\")\n",
    "    for i in range(5):\n",
    "        print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
